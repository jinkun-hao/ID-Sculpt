<!DOCTYPE html>
<html>
<head>

  <style> .results-carousel .item img { width: 512px; height: 512px; } </style>
  <meta charset="utf-8">
  <meta name="description"
        content="Portrait3D: 3D Head Generation from Single In-the-wild Portrait Image">
  <meta name="keywords" content="Video Generation, Camera Motion transfer, Camera-Object Motion, Disentanglement">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Portrait3D: 3D Head Generation from Single In-the-wild Portrait Image</title>

  <style>
    .custom-video-size {
      width: 800px;
      height: auto;
    }
    .responsive-video {
      width: 800%;
      height: auto;
      max-width: 800px;
    }
  </style>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>

  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">Portrait3D: 3D Head Generation from Single In-the-wild Portrait Image</h1>
            <div class="is-size-5 publication-authors">
              <span class="author-block">
                <a>Jinkun Hao</a><sup>1</sup>,</span>
              <span class="author-block">
                <a href="https://junshutang.github.io/">Junshu Tang</a><sup>1</sup>,</span>
              <span class="author-block">
                <a href="https://zhangzjn.github.io/">Jiangning Zhang</a><sup>2</sup>,</span>
              <span class="author-block">
                <a href="https://yiranran.github.io/">Ran Yi</a><sup>1</sup>,
              </span>
              <span class="author-block">
                <a>Yijia Hong</a><sup>1</sup>,
              </span>
              <span class="author-block">
                <a>Moran Li</a><sup>2</sup>,
              </span>
              <br />
              <span class="author-block">
                <a >Weijian Cao</a><sup>2</sup>,
              </span>
              <span class="author-block">
                <a>Yating Wang</a><sup>1</sup>,
              </span>
              <span class="author-block">
                <a >Lizhuang Ma</a><sup>1</sup>
              </span>
              <!-- <span class="author-block">
                <a href="http://sofienbouaziz.com">Sofien Bouaziz</a><sup>2</sup>,
              </span>
              <span class="author-block">
                <a href="https://www.danbgoldman.com">Dan B Goldman</a><sup>2</sup>,
              </span>
              <span class="author-block">
                <a href="https://homes.cs.washington.edu/~seitz/">Steven M. Seitz</a><sup>1,2</sup>,
              </span>
              <span class="author-block">
                <a href="http://www.ricardomartinbrualla.com">Ricardo Martin-Brualla</a><sup>2</sup>
              </span> -->
            </div>
  
            <!-- <div class="is-size-5 publication-authors">
              <span class="author-block"><sup>1</sup>University of Washington,</span>
              <span class="author-block"><sup>2</sup>Google Research</span>
            </div> -->
            <div class="is-size-5 publication-authors">
              <span class="author-block"><sup>1</sup>Shanghai Jiao Tong University</span><br />
              <span class="author-block"><sup>2</sup>Youtu Lab, Tencent </span><br />
            </div>
  
            <div class="column has-text-centered">
              <div class="publication-links">
                <!-- PDF Link. -->
                <span class="link-block">
                  <a href="https://jinkun-hao.github.io/Portrait3D/"
                     class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                        <i class="fas fa-file-pdf"></i>
                    </span>
                    <span>Paper</span>
                  </a>
                </span>
                <span class="link-block">
                  <a href="https://arxiv.org/abs/2406.16710"
                     class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                        <i class="ai ai-arxiv"></i>
                    </span>
                    <span>arXiv</span>
                  </a>
                </span>
                <!-- Code Link. -->
                <span class="link-block">
                  <a href="https://github.com/jinkun-hao/Portrait3D"
                     class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                        <i class="fab fa-github"></i>
                    </span>
                    <span>Code (comming soon)</span>
                    </a>
                </span>
                <!-- Dataset Link. -->
                <!-- <span class="link-block">
                  <a href="https://github.com/google/nerfies/releases/tag/0.1"
                     class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                        <i class="far fa-images"></i>
                    </span>
                    <span>Data</span>
                    </a> -->
              </div>
  
            </div>
          </div>
        </div>
      </div>
    </div>
  </section>

<section class="section" id="teaser">
  <div class="container is-max-desktop">

    <div class="columns is-centered">

      <div class="column has-text-centered">
        <div class="content">
          <h3 class="title is-4">
          </h3>
          <div class="item">
            <img src="./static/teaser.png" alt="Descriptive Alt Text" height="100%">
<!--            <video id="teaser" autoplay controls muted loop playsinline height="100%">-->
<!--              <source src="./static/videos/teaser.mp4"-->
<!--                      type="video/mp4">-->
<!--            </video>-->
<!--            <img src="./static/my_images/teaser.gif" alt="GIF 1" autoplay loop playsinline height="100%">-->
          </div>
        </div>
      </div>
      </div>
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">

        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            While recent works have achieved great success on one-shot 3D common object generation, high quality and fidelity 3D head generation from a single image remains a great challenge.
            Previous text-based methods for generating 3D heads were limited by text descriptions and image-based methods struggled to produce high-quality head geometry.
            To handle this challenging problem, we propose a novel framework, Portrait3D, to generate high-quality 3D heads while preserving their identities. Our work incorporates the identity information of the portrait image into three parts: 1) geometry initialization, 2) geometry sculpting, and 3) texture generation stages. 
            Given a reference portrait image, we first align the identity features with text features to realize ID-aware guidance enhancement, which contains the control signals representing the face information. 
            We then use the canny map, ID features of portrait image, and a pre-trained text-to-normal/depth diffusion model to generate ID-aware geometry supervision, and 3D-GAN inversion is employed to generate ID-aware geometry initialization. 
            Furthermore, with the ability to inject identity information into 3D head generation, we use ID-aware guidance to calculate ID-aware Score Distillation (ISD) for geometry sculpting. 
            For texture generation, we adopt the ID Consistent Texture Inpainting and Refinement which progressively expands the view for texture inpainting to obtain an initialization UV texture map. 
            We then use the id-aware guidance to provide image-level supervision for noisy multi-view images to obtain a refined texture map. Extensive experiments demonstrate that we can generate high-quality 3D heads with accurate geometry and texture from single in-the-wild portrait image.
        </div>
      </div>
    </div>
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Method</h2>
        <div class="columns is-centered">
          <img src="./static/framework.png" class="interpolation-image" alt="Interpolate start reference image.">
        </div>
        <div class="content has-text-justified">
          <p>
            Given a single in-the-wild portrait image, Portrait3D uses Identity-aware Head Guidance and Initialization to integrate identity information into the Geometry Sculpting stage. 
            In the texture generation stage, ID Consistent Texture Inpainting and Refinement is applied to generate a high-quality head texture, where we first use the inpainting method to generate a rough texture and then use image-level ID-aware supervision for texture refinement. 
            With these methods, we can generate high-quality 3D head models with consistent identities from a single in-the-wild face image.
        </div>
      </div>
    </div>
  </div>
</section>




<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <h2 class="title is-3">3D Head Generation from In-the-Wild Portrait Image</h2>
    </div>
    <div class="content has-text-justified">
      Given a single in-the-wild portrait image, Portrait3D can generate identity-consistant 3D head. Our results exhibit high-quality geometry and photorealistic textures.
    </div>
    <div class="hero-body">
      <video id="teaser" autoplay muted loop playsinline height="100%">
        <source src="./static/visual_result_new.mp4"
                type="video/mp4">
      </video>
    </div>
  </div>
</section>

<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <h2 class="title is-3">Comparision</h2>
    </div>
    <div class="content has-text-justified">
      Our method surpasses previous approaches in terms of the facial detail in head geometry, 3D consistency, and the realism of the texture.
    </div>
    <div class="hero-body">
      <video id="teaser" autoplay muted loop playsinline height="100%">
        <source src="./static/comparision_new.mp4"
                type="video/mp4">
      </video>
    </div>
  </div>
</section>

<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <h2 class="title is-3">Application</h2>
    </div>
    <div class="content has-text-justified">
      With the powerful capability of text-to-image diffusion models, using stylized stable diffusion versions, we can modify the text prompt during the texture generation stage to achieve stylized 3D head generation.
    </div>
    <div class="hero-body">
      <video id="teaser" autoplay muted loop playsinline height="100%">
        <source src="./static/stylization_new.mp4"
                type="video/mp4">
      </video>
    </div>
  </div>
</section>


<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>
@misc{hao2024portrait3d,
  title={Portrait3D: 3D Head Generation from Single In-the-wild Portrait Image}, 
  author={Jinkun Hao and Junshu Tang and Jiangning Zhang and Ran Yi and Yijia Hong and Moran Li and Weijian Cao and Yating Wang and Lizhuang Ma},
  year={2024},
  eprint={2406.16710},
  archivePrefix={arXiv},
}
</code></pre>
  </div>
</section>

<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
          <p>
            We borrow the <a href="https://github.com/nerfies/nerfies.github.io">source code</a> for our website.
            We sincerely appreciate Nerfies authors for their awesome templates.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>